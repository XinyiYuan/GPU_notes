- **[NSDI'23] Transparent GPU Sharing in Container Clouds for Deep Learning Workloads**
  - 容器广泛用于数据中心中的资源管理。
    - 支持容器云中的深度学习(DL)训练的一个常见实践是静态地将 GPU 完全绑定到容器上。
    - 由于生产中 DL 作业的资源需求多种多样，大量的 GPU 未得到充分利用。
    - 因此，GPU 集群具有较低的 GPU 利用率，由于排队，导致作业完成时间较长。
  - 我们提出 TGS (透明 GPU 共享) ，一个系统，提供透明的 GPU 共享到集装箱云中的 DL 训练。
    - 与最近 GPU 共享的应用层解决方案形成鲜明对比的是，TGS 在容器下的 OS 层运行。
    - 透明性允许用户使用任何软件来开发模型并在其容器中运行作业。
    - TGS 利用自适应速率控制和透明统一内存，同时实现高 GPU 利用率和性能隔离。
    - 它确保生产作业不会受到共享 GPU 上机会作业的严重影响。
    - 我们已经建立了 TGS，并将他与docker和kubernetes整合。实验结果表明:
      - TGS 对生产作业的吞吐量影响不大
      - TGS 为机会作业提供了与最先进的应用层解决方案 AntMan 相似的吞吐量，并且与现有的 OS 层解决方案 MPS 相比提高了15倍的吞吐量。
- **[ASPLOS ‘23] Lucid: A Non-intrusive, Scalable and Interpretable Scheduler for Deep Learning Training Jobs**
  - 虽然最近的深度学习工作负载调度器表现出很好的性能，但在实际应用中很难部署它们，是由于
    - 缺乏灵活的入侵方式、
    - 过高的集成和维护成本
    - 有限的可伸缩性
    - 不透明的决策过程
  - Lucid: 基于可解释模型的非侵入式深度学习工作负载调度器 。
    - 它由三个创新模块组成。
      - 首先，为了有效地收集作业度量和及时调试作业反馈，引入了一个二维优化剖析器。
      - 其次，Lucid 利用一种惰性包装策略来规避干扰。
      - 第三，Lucid 基于估计的作业优先级值和共享分数来编排资源，以实现有效的调度。
    - 此外，Lucid 通过设计良好的系统优化器促进模型性能维护和系统透明调整。
    - 我们的评估表明，与最先进的抢占式调度器 Tiresias 相比，Lucid 将平均作业完成时间减少了1.3倍。此外，它为实际部署提供了明确的系统解释和优秀的可伸缩性。
- **[EuroSys ‘23] Lyra: Elastic Scheduling for Deep Learning Clusters**
  - 训练和推理中的问题:
    - 当流量负载较低时，推理集群的 GPU 利用率较低
    - 由于缺乏资源，训练作业往往需要较长的排队时间
  - 我们引入了 Lyra ，一个新的集群调度器来解决这些问题。
    - Lyra 引入了容量贷款，将空闲推理 GPU 服务器贷款给训练工作。它进一步利用弹性扩展来扩展培训作业的 GPU 分配，以更好地利用借出的资源。
    - 容量借贷和弹性扩展为集群管理带来了新的挑战。
      - 当需要返回借出的服务器时，我们需要最小化作业抢占的数量
      - 当更多的 GPU 可用时，我们需要将它们分配到弹性作业，并最小化作业完成时间(JCT)
    - Lyra 使用基于原则的启发式方法来解决这些组合问题。
      - 它引入了服务器抢占成本的概念，并在服务器回收期间使用贪婪的方法降低这一成本。
      - 它进一步依赖于为弹性工作的每个额外工人定义的 JCT 缩减值，以多选择背包问题解决调度问题。
    - 在64-GPU 测试平台上的原型实现和超过50,000个生产作业的15天跟踪的大规模模拟表明
      - Aryl 在平均排队时间和 JCT 方面带来了1.53 x 和1.50 x 的减少
      - 集群调度器提高了高达26.9% 的集群使用率